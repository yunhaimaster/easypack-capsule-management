import { NextRequest, NextResponse } from 'next/server'

export const dynamic = 'force-dynamic'

const OPENROUTER_API_URL = process.env.OPENROUTER_API_URL || 'https://openrouter.ai/api/v1/chat/completions'

const MODEL_CATALOG = [
  { id: 'deepseek/deepseek-chat-v3.1', name: 'DeepSeek Chat v3.1' },
  { id: 'openai/gpt-4.1-mini', name: 'OpenAI GPT-4.1 Mini' },
  { id: 'x-ai/grok-4-fast', name: 'xAI Grok 4 Fast' }
]

export async function POST(request: NextRequest) {
  try {
    const {
      targetEffect,
      targetAudience,
      dosageForm,
      budget,
      enableReasoning,
      reasoningMap,
      singleModel
    } = await request.json()

    const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY
    if (!OPENROUTER_API_KEY) {
      return NextResponse.json(
        { success: false, error: 'AI æœå‹™æš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œè«‹ç¨å¾Œå†è©¦' },
        { status: 500 }
      )
    }

    const selectedModels = singleModel
      ? MODEL_CATALOG.filter(model => model.id === singleModel)
      : MODEL_CATALOG

    if (selectedModels.length === 0) {
      return NextResponse.json(
        { success: false, error: 'æœªæŒ‡å®šæœ‰æ•ˆçš„æ¨¡å‹' },
        { status: 400 }
      )
    }

    const systemPrompt = `ä½ æ˜¯è† å›Šä»£å·¥å» çš„ç ”ç™¼é¡§å• AIï¼Œæ ¹æ“šå®¢æˆ¶éœ€æ±‚ç”Ÿæˆç¬¦åˆè† å›ŠçŒè£ä»£å·¥å ´æ™¯çš„å°ˆæ¥­é…æ–¹ã€‚è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹æ¡†æ¶è¼¸å‡ºï¼Œä¸¦ä»¥ç¹é«”ä¸­æ–‡å›ç­”ï¼š

ç”¨æˆ¶éœ€æ±‚ï¼š
- ç›®æ¨™åŠŸæ•ˆï¼š${targetEffect}
- ç›®æ¨™å—çœ¾ï¼š${targetAudience || 'ä¸€èˆ¬æˆäºº'}
- åŠ‘å‹ï¼šè† å›Šï¼ˆå›ºå®šï¼‰
- ç‰¹åˆ¥è¦æ±‚ï¼š${budget || 'ç„¡ç‰¹æ®Šè¦æ±‚'}

ğŸ¯ è¼¸å‡ºæ¡†æ¶

## 1. é…æ–¹åŸºæœ¬è³‡è¨Š
- å°ˆæ¥­ç”¢å“åç¨±ï¼ˆä¸è¦ç›´æ¥ç”¨ç”¨æˆ¶è¼¸å…¥ï¼‰
- ç”¢å“æè¿°èˆ‡åŠŸæ•ˆèªªæ˜
- ä»£å·¥å®šä½èªªæ˜
- å»£å‘Šèªå»ºè­°ï¼ˆç°¡çŸ­ã€åˆè¦ã€ä¸æ¶‰é†«ç™‚ï¼‰

## 2. é…æ–¹åŸæ–™ï¼ˆè¡¨æ ¼ï¼šåŸæ–™ | åŠ‘é‡ | åŠŸèƒ½ | å‚™è¨»ï¼‰
- ä¸»æˆåˆ†ï¼šåŸºæ–¼åŠŸæ•ˆéœ€æ±‚
- è¼”æ–™ï¼šåƒ…é™å¸¸è¦‹çŒè£ç”¨ï¼ˆMCCã€éº¥èŠ½ç³Šç²¾ã€äºŒæ°§åŒ–çŸ½ã€ç¡¬è„‚é…¸é‚ï¼‰ï¼Œä¸¦èªªæ˜ä½œç”¨
- è¨»æ˜å»ºè­°ä¾†æºï¼ˆå°ˆåˆ©ç‰ˆ/å¸¸è¦åŸæ–™ï¼‰

## 3. è† å›Šè¦æ ¼å»ºè­°
- è¡¨æ ¼å‘ˆç¾ï¼šåŸæ–™é‡é‡ã€å‡è¨­å †ç©å¯†åº¦ã€é«”ç© â†’ æ··åˆç¸½é«”ç©
- æ ¹æ“šç²‰åŠ‘é«”ç©ï¼Œé¸æ“‡åˆé©çš„è† å›Šè™Ÿï¼ˆé™ 00ã€0ã€1ï¼Œä¸¦å«å®‰å…¨ä¿‚æ•¸ï¼‰
- å»ºè­°è† å›Šææ–™ï¼ˆæ˜è† /HPMCï¼‰èˆ‡é¡è‰²ï¼ˆè€ƒæ…®ç²‰æœ«é€è‰²/æŸ“è‰²é¢¨éšªï¼‰

## 4. åŠŸæ•ˆèˆ‡å®‰å…¨è©•åˆ†
- åŠŸæ•ˆè©•åˆ†ï¼ˆ1â€“10 åˆ†ï¼‰ï¼Œçµ¦å‡ºä¾æ“šï¼ˆæ–‡ç»/å‚³çµ±ä½¿ç”¨ï¼‰
- å®‰å…¨è©•åˆ†ï¼ˆ1â€“10 åˆ†ï¼‰ï¼Œè©•ä¼°é…ä¼èˆ‡é¢¨éšª
- è©•åˆ†ç†ç”±ï¼ˆç°¡è¿°ï¼‰

## 5. ä»£å·¥ç”Ÿç”¢å»ºè­°
- çŒè£å¯è¡Œæ€§ï¼ˆæµå‹•æ€§/æ˜¯å¦éœ€è£½ç²’ï¼‰
- ç”Ÿç”¢å·¥è—èˆ‡è³ªæ§æ³¨æ„é»
- åŒ…è£å»ºè­°ï¼ˆç“¶è£/æ³¡ç½©ï¼Œå« MOQ åƒè€ƒï¼‰

## 6. æ³•è¦èˆ‡åˆè¦æ€§
- é‡å°é¦™æ¸¯å¿…é ˆéµå®ˆçš„æ¨™ç±¤è¦ç¯„èˆ‡ç¦é™ç”¨è¦æ±‚
- å€åˆ†ã€Œå¿…é ˆæ¨™ç¤ºã€ã€Œå»ºè­°æ¨™ç¤ºã€ã€Œç¦æ­¢æ¨™ç¤ºã€
- æŒ‡å‡ºæ½›åœ¨éœ€è¦èª¿æ•´çš„æˆåˆ†ï¼ˆå¦‚éŠ·å¾€å¤§é™¸æˆ–æ­ç¾ï¼‰

âš ï¸ æ³¨æ„ï¼šç”Ÿæˆçš„é…æ–¹åƒ…ä¾›ç†è«–åƒè€ƒï¼Œä¸èƒ½è¦–ç‚ºé†«ç™‚å»ºè­°ï¼Œæœ€çµ‚éœ€çµåˆæ³•è¦èˆ‡å¯¦é©—é©—è­‰ã€‚`

    const basePayload = {
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: `è«‹ç‚ºæˆ‘ç”Ÿæˆä¸€å€‹${targetEffect}çš„${dosageForm || 'è† å›Š'}é…æ–¹` }
      ],
      max_tokens: 8000,
      temperature: 0.3,
      top_p: 0.95,
      frequency_penalty: 0.0,
      presence_penalty: 0.0,
      stream: true
    }

    const encoder = new TextEncoder()

    const stream = new ReadableStream({
      async start(controller) {
        const sendEvent = (event: string, data: Record<string, unknown>) => {
          controller.enqueue(encoder.encode(`event: ${event}\ndata: ${JSON.stringify(data)}\n\n`))
        }

        await Promise.all(
          selectedModels.map(async (model) => {
            sendEvent('start', { modelId: model.id, modelName: model.name })

            try {
              const response = await fetch(OPENROUTER_API_URL, {
                method: 'POST',
                headers: {
                  'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
                  'Content-Type': 'application/json',
                  'HTTP-Referer': process.env.NEXT_PUBLIC_APP_URL || 'https://easypack-capsule-management.vercel.app',
                  'X-Title': `Easy Health AI Recipe Generator (${model.name})`
                },
                body: JSON.stringify({
                  ...basePayload,
                  model: model.id
                  // Removed all reasoning/thinking parameters - models run as-is
                })
              })

              if (!response.ok) {
                const errorText = await response.text()
                throw new Error(errorText || 'æ¨¡å‹è«‹æ±‚å¤±æ•—')
              }

              if (!response.body) {
                throw new Error('æ¨¡å‹æ²’æœ‰è¿”å›ä»»ä½•è³‡æ–™')
              }

              const reader = response.body.getReader()
              const decoder = new TextDecoder()
              let buffer = ''
              let modelCompleted = false

              while (true) {
                const { done, value } = await reader.read()
                if (done) break
                buffer += decoder.decode(value, { stream: true })

                const events = buffer.split('\n\n')
                buffer = events.pop() || ''

                for (const eventBlock of events) {
                  const lines = eventBlock.split('\n')
                  let dataPayload = ''

                  for (const line of lines) {
                    if (line.startsWith('data:')) {
                      dataPayload += line.replace('data:', '').trim()
                    }
                  }

                  if (!dataPayload) continue

                  if (dataPayload === '[DONE]') {
                    modelCompleted = true
                    sendEvent('done', { modelId: model.id })
                    continue
                  }

                  try {
                    const parsed = JSON.parse(dataPayload)
                    const delta = parsed.choices?.[0]?.delta?.content
                    if (delta) {
                      sendEvent('delta', { modelId: model.id, delta })
                    }
                  } catch (_err) {
                    // å¿½ç•¥è§£æéŒ¯èª¤
                  }
                }
              }

              if (!modelCompleted) {
                sendEvent('done', { modelId: model.id })
              }
            } catch (error) {
              const message = error instanceof Error ? error.message : 'æœªçŸ¥éŒ¯èª¤'
              sendEvent('error', { modelId: model.id, error: message })
            }
          })
        )

        sendEvent('close', { completed: true })
        controller.close()
      }
    })

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache, no-transform',
        Connection: 'keep-alive'
      }
    })
  } catch (error) {
    console.error('AI é…æ–¹ç”ŸæˆéŒ¯èª¤:', error)
    return NextResponse.json(
      { success: false, error: 'é…æ–¹ç”Ÿæˆå¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦' },
      { status: 500 }
    )
  }
}