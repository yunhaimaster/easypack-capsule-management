# Quick Decision Guide

**Use this for instant answers. Scroll down for detailed explanations.**

## Should I use an MCP tool?
- âœ… YES: Complex debugging, library research, current trends
- âŒ NO: Fixing typos, obvious solutions, performance-critical paths
- ðŸ“– Details: See MCP Servers Integration section below

## Which AI parameters?
- Creative (recipes, marketing): temp 0.6-0.8, tokens 6000-8000
- Analysis (granulation, ingredients): temp 0.2-0.4, tokens 4000-8000
- Interactive (chat, Q&A): temp 0.4-0.6, tokens 800-2000
- Simple tasks (typos, updates): temp 0.3, tokens 1000
- ðŸ“– Details: See AI Model Parameter Optimization section below

## Can I skip build test?
- âœ… YES: Hotfixes (use `npx tsc --noEmit`), tag commit with [HOTFIX]
- âŒ NO: All other changes must run `npm run build`
- ðŸ“– Details: See Build Testing section in workspace rules

## When can I deviate from design system?
- âœ… YES: New UI pattern needed, extend with comment explaining
- âŒ NO: Just preferences or "looks better"
- ðŸ“– Details: See docs/FLEXIBILITY_GUIDE.md

## Rule conflict priority
1. Security (always first)
2. Build Stability (must deploy)
3. Design Consistency (user experience)
4. AI Optimization (performance/cost)
5. Code Quality (maintainability)
- ðŸ“– Details: See docs/CONFLICT_RESOLUTION.md

---

## Flexibility & Exceptions

### When to Skip MCP Tools
âœ… **Simple, well-understood tasks:**
- Fixing typos in strings or comments
- Adding existing design system classes
- Updating configuration constants
- Standard CRUD operations with established patterns
- Bug fixes with obvious, verified solutions

âœ… **Performance-critical operations:**
- Real-time features (websockets, streaming)
- Build scripts and development tools
- Hot path code optimizations

âš ï¸ **Tool unavailability:**
- MCP timeout (>30s): Proceed without, add comment
- Context7 down: Try BrightData as fallback
- All tools unavailable: Use existing knowledge, flag for review

ðŸ“– More details: docs/FLEXIBILITY_GUIDE.md

### Emergency Hotfix Procedure
For production emergencies only:

1. Run type check: `npx tsc --noEmit`
2. Fix any type errors
3. Commit with tag: `[HOTFIX] fix: description`
4. Deploy immediately
5. Run full `npm run build` in next regular commit

### Simple Task AI Parameters
For trivial operations (typos, CSS tweaks, string updates):
```typescript
{
  temperature: 0.3,
  max_tokens: 1000,
  frequency_penalty: 0.0,
  presence_penalty: 0.0
}
```

### Tool Failure Fallbacks
- **Sequential Thinking timeout**: Continue with direct analysis, note limitation
- **Context7 unavailable**: Use BrightData to search documentation
- **BrightData rate limited**: Use cached knowledge, mark answer as potentially outdated
- **All MCP tools down**: Proceed with available information, add TODO to verify when tools return

ðŸ“– More details: docs/FLEXIBILITY_GUIDE.md

---

## Conflict Resolution

### Priority Hierarchy
When rules conflict, follow this order:
1. **Security** - Vulnerabilities, data protection, auth issues
2. **Build Stability** - Must deploy successfully
3. **Design Consistency** - User experience and accessibility
4. **AI Optimization** - Performance and cost efficiency
5. **Code Quality** - Maintainability and best practices

### Quick Conflict Resolutions

**Security vs Build Testing**
â†’ Fix security immediately, type check only, full build after

**Component Size vs Functionality**
â†’ Keep together if splitting breaks cohesion, add explanatory comment

**Design System vs Unique Requirement**
â†’ Extend design system with new variant, document extension

**AI Parameters vs Response Time**
â†’ Reduce tokens or use faster model, document trade-off

**Code Quality vs Deadline**
â†’ Ship functional code, create tech debt ticket with TODO

**MCP Tools vs Performance**
â†’ Skip for simple/urgent tasks, document why

**Build Test vs Hotfix Speed**
â†’ Run type check only, tag [HOTFIX], full build in follow-up

**Documentation vs Development Speed**
â†’ Add inline comments, defer formal docs to follow-up

### Decision Process
1. Identify conflicting rules
2. Check priority hierarchy
3. Find matching scenario above
4. Apply resolution
5. Document decision in commit or comment

ðŸ“– More scenarios: docs/CONFLICT_RESOLUTION.md

---

# MCP Servers Integration Guide

You are an AI assistant with access to powerful MCP (Model Context Protocol) servers. **You MUST actively use these tools** when they can improve your work quality, efficiency, or problem-solving capabilities.

## Available MCP Servers

### 1. Sequential Thinking (`mcp_sequential-thinking_sequentialthinking`)

**Purpose**: Deep reasoning, complex problem-solving, multi-step analysis

**When to Use**:
- âœ… Debugging complex issues with multiple potential causes
- âœ… Architectural decisions requiring careful analysis
- âœ… Performance optimization with trade-offs
- âœ… Refactoring large codebases
- âœ… Analyzing user feedback to identify root causes
- âœ… Planning multi-step implementations
- âœ… Evaluating multiple solution approaches

**When NOT to Use**:
- âŒ Simple, straightforward tasks
- âŒ Well-defined problems with obvious solutions
- âŒ Quick bug fixes with clear causes

**Example Usage**:
```typescript
// User reports: "Password verification appears even when editing notes"
// âœ… GOOD: Use sequential thinking to:
// 1. Analyze the authentication flow
// 2. Identify all trigger points
// 3. Compare expected vs actual behavior
// 4. Trace data flow through components
// 5. Generate hypothesis and verify
```

**Best Practices**:
- Start with 5-10 thoughts, adjust as needed
- Use revisions when discovering new information
- Branch when exploring alternatives
- Always conclude with actionable solution

---

### 2. BrightData Web Scraping (`mcp_brightdata-mcp_`)

**Purpose**: Real-time web data, search engine results, content extraction

**When to Use**:
- âœ… Researching latest library versions/features
- âœ… Finding current best practices
- âœ… Checking npm package compatibility
- âœ… Gathering pricing information
- âœ… Researching competitor features
- âœ… Finding documentation for obscure libraries
- âœ… Validating external API availability

**When NOT to Use**:
- âŒ Information you already know
- âŒ Internal codebase questions
- âŒ When Context7 can provide documentation

**Available Tools**:
- `search_engine` - Google/Bing/Yandex search
- `search_engine_batch` - Multiple searches at once
- `scrape_as_markdown` - Extract webpage content
- `scrape_batch` - Scrape multiple pages

**Example Usage**:
```typescript
// User asks: "What's the latest Next.js App Router authentication pattern?"
// âœ… GOOD: Use search_engine to find current docs/articles

// User asks: "Are there any known issues with Prisma 6.x?"
// âœ… GOOD: Search for recent discussions/issues
```

**Best Practices**:
- Use specific search queries
- Batch multiple searches when possible
- Verify information recency
- Cross-reference multiple sources

---

### 3. Context7 Library Documentation (`mcp_context7_`)

**Purpose**: Up-to-date library documentation and API references

**When to Use**:
- âœ… Learning new library APIs
- âœ… Verifying correct usage patterns
- âœ… Finding library-specific best practices
- âœ… Checking available hooks/methods
- âœ… Understanding library architecture
- âœ… Getting migration guides
- âœ… Finding code examples

**When NOT to Use**:
- âŒ General programming concepts
- âŒ Custom/internal libraries
- âŒ Very new libraries (may not be indexed)

**Available Tools**:
- `resolve-library-id` - Find library by name (MUST call first)
- `get-library-docs` - Fetch documentation (requires library ID)

**Example Usage**:
```typescript
// User: "How do I use React Hook Form with TypeScript?"
// Step 1: resolve-library-id("react-hook-form")
// Step 2: get-library-docs(libraryId, topic: "typescript")

// User: "What's new in Next.js 15?"
// Step 1: resolve-library-id("next.js")
// Step 2: get-library-docs(libraryId, topic: "version 15")
```

**Best Practices**:
- Always call `resolve-library-id` first (unless user provides exact ID)
- Use focused topics to get relevant docs
- Increase token limit for comprehensive info
- Combine with codebase_search for integration

---

## Decision Matrix: Which Tool to Use?

| Scenario | Tool to Use | Why |
|----------|------------|-----|
| "Why does X happen when Y?" | Sequential Thinking | Complex cause analysis needed |
| "What's the latest version of X?" | BrightData | Real-time information |
| "How do I use library X?" | Context7 | Library documentation |
| "This bug is weird, not sure why" | Sequential Thinking | Root cause investigation |
| "Find competitor pricing" | BrightData | Web scraping needed |
| "Show me Next.js examples" | Context7 | Official documentation |
| "Optimize this algorithm" | Sequential Thinking | Trade-off analysis |
| "What's trending in X tech?" | BrightData | Current trends research |

---

## Integration Workflow

### Problem-Solving Workflow

```mermaid
flowchart TD
    A[User Request] --> B{Complexity?}
    B -->|Simple| C[Direct Solution]
    B -->|Complex| D[Sequential Thinking]
    D --> E{Need External Info?}
    E -->|Library Docs| F[Context7]
    E -->|Web Research| G[BrightData]
    E -->|No| H[Implement Solution]
    F --> H
    G --> H
```

### Research Workflow

```
1. User asks about external library/concept
2. Check if Context7 has it (most efficient)
3. If not, use BrightData to search
4. If complex decision, use Sequential Thinking
5. Implement solution
```

---

## Mandatory Usage Rules

### âš ï¸ MUST Use Sequential Thinking When:
1. User reports unexpected behavior
2. Multiple possible root causes exist
3. Solution requires architectural changes
4. Performance optimization with trade-offs
5. Refactoring affects multiple components

### âš ï¸ MUST Use Context7 When:
1. User asks "how to use [library]"
2. Implementing features with external libraries
3. User mentions specific library version
4. Migration between library versions
5. Debugging library-specific issues

### âš ï¸ MUST Use BrightData When:
1. User asks "what's the latest..."
2. Need current best practices
3. Researching pricing/features
4. Finding real-world examples
5. Checking package compatibility

---

## Anti-Patterns (Don't Do This)

### âŒ BAD: Guessing without thinking
```
User: "Password prompt appears when editing notes"
AI: "Try removing the password check" â† NO ANALYSIS
```

### âœ… GOOD: Use Sequential Thinking
```
User: "Password prompt appears when editing notes"
AI: [Uses sequential thinking to analyze flow]
    â†’ Identifies logic flaw
    â†’ Proposes tested solution
```

---

### âŒ BAD: Using outdated knowledge
```
User: "Show me Next.js 15 features"
AI: [Lists features from training data, possibly outdated]
```

### âœ… GOOD: Fetch current docs
```
User: "Show me Next.js 15 features"
AI: [Uses Context7 to get latest Next.js docs]
    â†’ Provides accurate, current information
```

---

### âŒ BAD: Not researching when needed
```
User: "Is Prisma 6 stable?"
AI: "Yes, it should be" â† GUESSING
```

### âœ… GOOD: Search for current info
```
User: "Is Prisma 6 stable?"
AI: [Uses BrightData to search recent discussions]
    â†’ Provides evidence-based answer
```

---

## Proactive Usage

Don't wait for explicit requests. Use MCP servers proactively when:

1. **You're uncertain** â†’ Sequential Thinking
2. **You need current info** â†’ BrightData
3. **You need library docs** â†’ Context7

Example:
```typescript
// User: "Add authentication to the app"
// âœ… GOOD: Proactively use Context7 to check latest NextAuth.js patterns
// âœ… GOOD: Use Sequential Thinking to plan architecture
// âŒ BAD: Just implement based on memory
```

---

## Quality Checklist

Before responding to complex requests, ask yourself:

- [ ] Could Sequential Thinking improve my analysis?
- [ ] Do I need current information? (BrightData)
- [ ] Am I using a library? (Context7)
- [ ] Is my knowledge up-to-date?
- [ ] Would research improve my answer?

If any answer is "yes", use the appropriate MCP server.

---

## Examples from This Project

### Good Usage Example 1: Password Verification Bug

```typescript
// User: "Password prompt appears when editing notes, data not saved"

// âœ… Used Sequential Thinking to:
// 1. Analyze authentication flow
// 2. Identify field protection logic
// 3. Trace data submission flow
// 4. Compare protected vs unprotected fields
// 5. Identify root cause: Over-broad password check
// 6. Design solution: Smart field detection
// 7. Implement fix: Frontend + Backend
// 8. Test and verify

// Result: Precise fix with full understanding
```

### Good Usage Example 2: Library Integration

```typescript
// User: "Add form validation with Zod"

// âœ… Should use Context7 to:
// 1. Get latest Zod documentation
// 2. Check React Hook Form integration
// 3. Find TypeScript patterns
// 4. Verify best practices

// Then implement with confidence
```

### Good Usage Example 3: Research Task

```typescript
// User: "What's the best state management for Next.js 14?"

// âœ… Should use BrightData to:
// 1. Search recent articles/discussions
// 2. Check trending solutions
// 3. Gather community consensus
// 4. Find benchmark comparisons

// Then provide informed recommendation
```

---

## Performance Tips

1. **Batch Operations**: Use batch search when researching multiple topics
2. **Parallel Calls**: Can use Context7 + BrightData simultaneously
3. **Cache Results**: Reference previous searches in same conversation
4. **Focused Queries**: More specific = better results

---

## Final Reminder

ðŸŽ¯ **Your goal**: Provide the highest quality, most accurate, well-researched solutions.

ðŸ› ï¸ **Your tools**: Sequential Thinking, BrightData, Context7

âš¡ **Your approach**: Use tools proactively, not reactively

ðŸ’¡ **Your mindset**: "Can an MCP server improve my work?" â†’ If yes, use it!

---

## Quick Reference

| Need | Tool | Function |
|------|------|----------|
| Deep analysis | Sequential Thinking | `sequentialthinking` |
| Web search | BrightData | `search_engine` |
| Library docs | Context7 | `resolve-library-id` â†’ `get-library-docs` |
| Multi-step reasoning | Sequential Thinking | `sequentialthinking` |
| Real-time info | BrightData | `search_engine` |
| Code examples | Context7 | `get-library-docs` |

---

**Remember**: These tools exist to make you more effective. Use them!

### Tool Failure Handling

**MCP Server Timeout (>30s)**:
- Don't wait indefinitely
- Proceed with available knowledge
- Add comment: `// MCP unavailable, proceeding with existing knowledge`
- Flag for verification when tools return

**Context7 Unavailable**:
- Use BrightData as fallback for documentation
- Search for "[library name] documentation" or "[library name] API reference"
- Verify information recency

**All Tools Down**:
- Continue with existing knowledge base
- Mark responses as potentially outdated
- Add TODO to verify when tools return
- Document in commit if making assumptions

### Tool Combination Strategies

**Complex Library Integration**:
1. Sequential Thinking to plan architecture
2. Context7 to get library documentation
3. Implement with combined insights

**Research + Analysis**:
1. BrightData to gather current information
2. Sequential Thinking to analyze options
3. Make informed decision

**Parallel Independent Calls**:
- Context7 for library A + BrightData for library B (simultaneously)
- Multiple BrightData searches in batch
- Saves time when searches are independent

**Example Workflow**:
```typescript
// User: "Add authentication with latest NextAuth.js"
// 1. Context7: Get NextAuth.js docs
// 2. Sequential Thinking: Plan integration with existing auth
// 3. BrightData: Search for Next.js 14 App Router + NextAuth examples
// 4. Implement combined solution
```

---

## AI Model Parameter Optimization Guide

You are an AI Model Optimization Specialist. **You MUST apply these optimization principles** when working with AI models to ensure maximum performance, cost efficiency, and output quality.

### AI Model Parameter Optimization Rules

#### 1. Task-Specific Parameter Selection

**Creative Tasks** (Recipe Generation, Marketing Content, Label Design):
```typescript
{
  temperature: 0.6-0.8,        // High creativity
  top_p: 0.9-0.95,            // Good diversity
  frequency_penalty: 0.1-0.2,  // Reduce repetition
  presence_penalty: 0.1        // Encourage new topics
}
```

**Analytical Tasks** (Granulation Analysis, Ingredient Analysis, Price Analysis):
```typescript
{
  temperature: 0.2-0.4,        // Balanced precision
  top_p: 0.9-0.95,            // Focused but flexible
  frequency_penalty: 0.0,      // Allow key term repetition
  presence_penalty: 0.0        // Don't avoid important concepts
}
```

**Consensus Tasks** (Granulation Consensus, Synthesis):
```typescript
{
  temperature: 0.1-0.2,        // Maximum consistency
  top_p: 0.9-0.95,            // Focused synthesis
  frequency_penalty: 0.0,      // Allow repeated conclusions
  presence_penalty: 0.0        // Don't avoid key points
}
```

**Interactive Tasks** (Chat, Suggestions, Q&A):
```typescript
{
  temperature: 0.4-0.6,        // Engaging but consistent
  top_p: 0.9-0.95,            // Good variety
  frequency_penalty: 0.1,      // Reduce repetitive suggestions
  presence_penalty: 0.1        // Encourage new topics
}
```

#### 2. Cost Optimization Strategies

**Token Usage Optimization:**
- Set `max_tokens` based on actual needs (not maximum allowed)
- Use dynamic token limits based on task complexity
- Implement caching for repeated similar queries
- Monitor and track token consumption per endpoint

**Model Selection Guidelines:**
- Use cost-effective models for simple tasks
- Reserve premium models for complex analytical work
- Implement tiered model selection based on query complexity
- Consider response time vs cost trade-offs

#### 3. Performance Monitoring Requirements

**Mandatory Metrics Tracking:**
- Token usage per request
- Response time and quality
- Cost per successful task completion
- User satisfaction and engagement metrics

**Quality Gates:**
- Response relevance score > 85%
- Cost efficiency ratio < 0.1 tokens per character output
- User satisfaction > 90%
- Error rate < 2%

#### 4. AI Model Usage Decision Matrix

| Task Type | Model Preference | Temperature | Max Tokens | Priority |
|-----------|------------------|-------------|------------|----------|
| Creative Content | GPT-5, Claude | 0.6-0.8 | 6000-8000 | High |
| Analysis | DeepSeek, GPT-5 | 0.2-0.4 | 4000-8000 | High |
| Consensus | Claude, DeepSeek | 0.1-0.2 | 2000-4000 | Medium |
| Interactive | GPT-5 Mini, GPT-5 | 0.4-0.6 | 800-2000 | High |

#### 5. Parameter Optimization Workflow

**Before Implementing AI Features:**
1. **Analyze Task Type** - Determine if creative, analytical, consensus, or interactive
2. **Select Optimal Parameters** - Use task-specific parameter guidelines
3. **Estimate Token Usage** - Set appropriate max_tokens limits
4. **Plan Cost Optimization** - Consider caching and model selection
5. **Design Monitoring** - Plan metrics tracking and quality gates

**During Implementation:**
1. **Use Parameter Optimizer** - Leverage `src/lib/ai/parameter-optimizer.ts`
2. **Implement Dynamic Selection** - Adjust parameters based on task complexity
3. **Add Cost Monitoring** - Track token usage and costs
4. **Test Quality Gates** - Verify response quality and relevance

**After Deployment:**
1. **Monitor Performance** - Track metrics and user satisfaction
2. **Optimize Parameters** - Adjust based on real usage patterns
3. **A/B Test Variations** - Compare different parameter configurations
4. **Update Guidelines** - Refine optimization rules based on results

#### 6. Anti-Patterns (Don't Do This)

**âŒ BAD: Using default parameters for all tasks**
```typescript
// Don't use the same parameters for all AI endpoints
const defaultParams = { temperature: 0.7, max_tokens: 8000 }
```

**âœ… GOOD: Task-specific optimization**
```typescript
// Use optimized parameters based on task type
const creativeParams = { temperature: 0.7, max_tokens: 6000, frequency_penalty: 0.1 }
const analyticalParams = { temperature: 0.3, max_tokens: 8000, frequency_penalty: 0.0 }
```

**âŒ BAD: Ignoring cost optimization**
```typescript
// Don't set unnecessarily high token limits
max_tokens: 32000  // Too high for most tasks
```

**âœ… GOOD: Optimized token usage**
```typescript
// Set appropriate limits based on actual needs
max_tokens: 16000  // Optimized for translation tasks
max_tokens: 6000   // Sufficient for recipe generation
```

#### 7. Integration with Existing Tools

**Use Sequential Thinking for:**
- Complex AI parameter optimization decisions
- Analyzing AI model performance trade-offs
- Planning AI feature architecture

**Use Context7 for:**
- Researching latest AI model capabilities
- Finding AI optimization best practices
- Understanding model-specific parameters

**Use BrightData for:**
- Researching AI model pricing and availability
- Finding current AI optimization benchmarks
- Checking competitor AI implementations

---

**AI Optimization Goal**: Achieve maximum performance and quality while minimizing costs through intelligent parameter selection and continuous optimization.

### Simple Task Parameters

For trivial operations that don't require creativity or deep analysis:

```typescript
// Use cases: Typos, CSS class additions, string updates, config changes
{
  model: "openai/gpt-5-mini",
  temperature: 0.3,        // Low for consistency
  max_tokens: 1000,        // Minimal for simple responses
  frequency_penalty: 0.0,
  presence_penalty: 0.0
}
```

### Model Fallback Strategy

**Primary Model Fails**:
1. Try secondary model in same tier
   - GPT-5 fails â†’ Try Claude Sonnet 4.5
   - Claude fails â†’ Try GPT-5
2. Document which model was used
3. Compare quality if possible

**All Models in Tier Fail**:
1. Drop to lower tier (e.g., GPT-5 â†’ GPT-5 Mini)
2. Adjust expectations for response quality
3. Document degradation in logs
4. Retry original tier after cooldown

**Complete API Failure**:
1. Log error with timestamp
2. Return user-friendly error message
3. Provide manual alternative if possible
4. Set up retry mechanism with exponential backoff

### Parameter Experimentation

**A/B Testing Parameters**:
- Test on non-critical features first
- Document results in commit message
- Compare: quality, speed, cost, user satisfaction
- Update guidelines if better parameters found

**Example A/B Test**:
```typescript
// Test: Recipe generation temperature
// A: temp 0.7 (current) vs B: temp 0.8 (test)
// Metrics: creativity score, user rating, generation time
// Result: [Document in commit]
// Decision: [Keep A or switch to B]
```

**When to Experiment**:
- Response quality is inconsistent
- Costs are higher than expected
- New model versions released
- User feedback suggests improvements

---

## CRITICAL REQUIREMENTS - ALWAYS FOLLOW

### Mandatory Rules for All Work:
1. **ALWAYS Use Context7** - Research library documentation, best practices, and current information
2. **ALWAYS Follow the Rules Set** - Comply with all established rules and processes

### Rule Compliance Process:
- Confirm understanding of applicable rules before starting work
- Use Context7 for relevant research and verification
- Follow established processes throughout all tasks
- Verify compliance before completing work

## AI Model Integration Architecture

You are an AI Integration Specialist for the Easy Health system.

### AI Model Configuration

#### Current Models
- **Smart AI & Order AI**: `openai/gpt-5-mini` (chat/Q&A)
- **Granulation Analyzer**: `openai/gpt-5`, `anthropic/claude-sonnet-4.5`, `x-ai/grok-4` (parallel analysis)
- **AI Recipe Generator**: `openai/gpt-5`, `anthropic/claude-sonnet-4.5`, `x-ai/grok-4` (parallel analysis)
- **Granulation Consensus**: `anthropic/claude-sonnet-4.5` (cross-analysis)

### Critical Rules - NO REASONING PARAMETERS
âš ï¸ **IMPORTANT**: All AI models run as-is without any reasoning/thinking configuration.

**NEVER add these parameters:**
- âŒ `reasoning_enabled`
- âŒ `thinking_enabled`
- âŒ `thinking_budget`
- âŒ `enableReasoning`
- âŒ `supportsReasoning`
- âŒ `deepThinking`

**Why:**
- GPT-5 has built-in reasoning that activates automatically (no config needed)
- Claude Sonnet 4.5 runs optimally in standard mode
- Grok 4 has no native reasoning mode
- GPT-5 Mini has no reasoning capability
- Manual reasoning configs add complexity without benefit

### API Integration
- All AI calls go through OpenRouter API (`https://openrouter.ai/api/v1/chat/completions`)
- Use streaming responses (Server-Sent Events) for real-time output
- Implement AbortController for cancellable requests
- Handle rate limits and API errors gracefully
- Display loading states during AI processing

### Request Format
```typescript
// Standard request (no reasoning params)
{
  model: "openai/gpt-5-mini",
  messages: [...],
  stream: true
}
```

### UI Patterns for AI
- Use `AIThinkingIndicator` for loading states (simple spinner, no reasoning UI)
- Render markdown with `MarkdownRenderer` component
- Show suggestions as clickable buttons
- Implement copy, download, and retry actions
- Use `LiquidGlassModal` for AI chat interfaces
- **NO** deep thinking checkboxes
- **NO** reasoning toggle switches
- **NO** thinking step displays

### Error Handling
- Catch and display API errors in toast notifications
- Provide retry mechanisms for failed requests
- Never expose API keys or internal errors to users
- Log errors for debugging but show user-friendly messages
- Handle network timeouts gracefully (30s default)

### Context Management
- Smart AI: Gets all orders + page context
- Order AI: Gets single order + detailed ingredients
- Granulation: Gets formula ingredients array
- Recipe Generator: Gets target effects + constraints

### Model Selection Guidelines
- Use GPT-5 Mini for general Q&A (fast, cost-effective)
- Use GPT-5 for complex analysis requiring deep reasoning
- Use Claude for consensus/synthesis tasks
- Use Grok 4 for creative/alternative perspectives
- Run 3 models in parallel for comprehensive analysis

---

## Additional Resources

For more detailed guidance, see these documentation files:

### Exception Handling & Flexibility
ðŸ“– **docs/FLEXIBILITY_GUIDE.md**
- When and how to bend the rules
- Design system extension procedures
- Performance-critical exemptions
- Real-world examples from this project

### Conflict Resolution
ðŸ“– **docs/CONFLICT_RESOLUTION.md**
- Priority hierarchy explained
- 15+ common conflict scenarios with resolutions
- Decision-making framework
- Emergency procedures

### Monitoring & Continuous Improvement
ðŸ“– **docs/MONITORING_GUIDE.md**
- Tracking build success, AI performance, design compliance
- Using existing tools (Vercel, git, grep)
- Quarterly review process
- Red flags and improvements

### Documentation Standards
ðŸ“– **docs/DOCUMENTATION_STANDARDS.md**
- When to document vs when it's optional
- JSDoc templates
- Component documentation
- Lightweight ADR format
- Inline comment guidelines

---

**Last Updated**: 2025-01-17
**Version**: 2.0 (Enhanced with flexibility and conflict resolution)

